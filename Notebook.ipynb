{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SET UP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.10.13\n",
      "\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "!python --version\n",
    "%conda config --set allow_conda_downgrades true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mERROR: Could not find a version that satisfies the requirement install (from versions: none)\u001b[0m\u001b[31m\n",
      "\u001b[0m\u001b[31mERROR: No matching distribution found for install\u001b[0m\u001b[31m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -r ./requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'stylegan2-pytorch (Python 3.7.16)' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'conda install -n stylegan2-pytorch ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": [
    "!python generate.py --outdir=out --trunc=1 --seeds=85,265,297 --network=https://nvlabs-fi-cdn.nvidia.com/stylegan2-ada-pytorch/pretrained/metfaces.pkl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#   CUSTOM TRAINING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Usage: dataset_tool.py [OPTIONS]\n",
      "\n",
      "  Convert an image dataset into a dataset archive usable with StyleGAN2 ADA\n",
      "  PyTorch.\n",
      "\n",
      "  The input dataset format is guessed from the --source argument:\n",
      "\n",
      "  --source *_lmdb/                    Load LSUN dataset\n",
      "  --source cifar-10-python.tar.gz     Load CIFAR-10 dataset\n",
      "  --source train-images-idx3-ubyte.gz Load MNIST dataset\n",
      "  --source path/                      Recursively load all images from path/\n",
      "  --source dataset.zip                Recursively load all images from dataset.zip\n",
      "\n",
      "  Specifying the output format and path:\n",
      "\n",
      "  --dest /path/to/dir                 Save output files under /path/to/dir\n",
      "  --dest /path/to/dataset.zip         Save output files into /path/to/dataset.zip\n",
      "\n",
      "  The output dataset format can be either an image folder or an uncompressed\n",
      "  zip archive. Zip archives makes it easier to move datasets around file\n",
      "  servers and clusters, and may offer better training performance on network\n",
      "  file systems.\n",
      "\n",
      "  Images within the dataset archive will be stored as uncompressed PNG.\n",
      "  Uncompresed PNGs can be efficiently decoded in the training loop.\n",
      "\n",
      "  Class labels are stored in a file called 'dataset.json' that is stored at\n",
      "  the dataset root folder.  This file has the following structure:\n",
      "\n",
      "  {\n",
      "      \"labels\": [\n",
      "          [\"00000/img00000000.png\",6],\n",
      "          [\"00000/img00000001.png\",9],\n",
      "          ... repeated for every image in the datase\n",
      "          [\"00049/img00049999.png\",1]\n",
      "      ]\n",
      "  }\n",
      "\n",
      "  If the 'dataset.json' file cannot be found, the dataset is interpreted as\n",
      "  not containing class labels.\n",
      "\n",
      "  Image scale/crop and resolution requirements:\n",
      "\n",
      "  Output images must be square-shaped and they must all have the same power-\n",
      "  of-two dimensions.\n",
      "\n",
      "  To scale arbitrary input image size to a specific width and height, use the\n",
      "  --width and --height options.  Output resolution will be either the original\n",
      "  input resolution (if --width/--height was not specified) or the one\n",
      "  specified with --width/height.\n",
      "\n",
      "  Use the --transform=center-crop or --transform=center-crop-wide options to\n",
      "  apply a center crop transform on the input image.  These options should be\n",
      "  used with the --width and --height options.  For example:\n",
      "\n",
      "  python dataset_tool.py --source LSUN/raw/cat_lmdb --dest /tmp/lsun_cat \\\n",
      "      --transform=center-crop-wide --width 512 --height=384\n",
      "\n",
      "Options:\n",
      "  --source PATH                   Directory or archive name for input dataset\n",
      "                                  [required]\n",
      "  --dest PATH                     Output directory or archive name for output\n",
      "                                  dataset  [required]\n",
      "  --max-images INTEGER            Output only up to `max-images` images\n",
      "  --resize-filter [box|lanczos]   Filter to use when resizing images for\n",
      "                                  output resolution  [default: lanczos]\n",
      "  --transform [center-crop|center-crop-wide]\n",
      "                                  Input crop/resize mode\n",
      "  --width INTEGER                 Output width\n",
      "  --height INTEGER                Output height\n",
      "  --help                          Show this message and exit.\n"
     ]
    }
   ],
   "source": [
    "!python dataset_tool.py --help"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/innoisys/GrigorisKarypidis/HAM10000_images_part_1/images.zip\n"
     ]
    }
   ],
   "source": [
    "dataset_path = \"/home/innoisys/GrigorisKarypidis/HAM10000_images_part_1/images.zip\"\n",
    "out_path = \"/home/innoisys/GrigorisKarypidis/stylegan2-ada-pytorch/out\"\n",
    "\n",
    "print(dataset_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/innoisys/GrigorisKarypidis/stylegan2-ada-pytorch/train.py\", line 538, in <module>\n",
      "    main() # pylint: disable=no-value-for-parameter\n",
      "  File \"/home/innoisys/anaconda3/envs/StyleGAN/lib/python3.10/site-packages/click/core.py\", line 1157, in __call__\n",
      "    return self.main(*args, **kwargs)\n",
      "  File \"/home/innoisys/anaconda3/envs/StyleGAN/lib/python3.10/site-packages/click/core.py\", line 1078, in main\n",
      "    rv = self.invoke(ctx)\n",
      "  File \"/home/innoisys/anaconda3/envs/StyleGAN/lib/python3.10/site-packages/click/core.py\", line 1434, in invoke\n",
      "    return ctx.invoke(self.callback, **ctx.params)\n",
      "  File \"/home/innoisys/anaconda3/envs/StyleGAN/lib/python3.10/site-packages/click/core.py\", line 783, in invoke\n",
      "    return __callback(*args, **kwargs)\n",
      "  File \"/home/innoisys/anaconda3/envs/StyleGAN/lib/python3.10/site-packages/click/decorators.py\", line 33, in new_func\n",
      "    return f(get_current_context(), *args, **kwargs)\n",
      "  File \"/home/innoisys/GrigorisKarypidis/stylegan2-ada-pytorch/train.py\", line 486, in main\n",
      "    run_desc, args = setup_training_loop_kwargs(**config_kwargs)\n",
      "  File \"/home/innoisys/GrigorisKarypidis/stylegan2-ada-pytorch/train.py\", line 111, in setup_training_loop_kwargs\n",
      "    args.training_set_kwargs.resolution = training_set.resolution # be explicit about resolution\n",
      "  File \"/home/innoisys/GrigorisKarypidis/stylegan2-ada-pytorch/training/dataset.py\", line 126, in resolution\n",
      "    assert self.image_shape[1] == self.image_shape[2]\n",
      "AssertionError\n"
     ]
    }
   ],
   "source": [
    "!python train.py --outdir={out_path} --data={dataset_path} --gpus=1\n",
    "!python train.py --outdir=~/out_path --data=~/mydataset.zip --gpus=1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
